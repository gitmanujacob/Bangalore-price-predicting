# -*- coding: utf-8 -*-
"""Bangalore_House_price_

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j7SHPxb6q2cZ8WmKN0OW3PVCtEDp5iCF

Import Data
"""

import pandas as pd
df=pd.read_csv("/content/Bengaluru_House_Data.csv")
df.head()

df.shape

"""checking null value & type"""

df.isna().sum()

df.dtypes

df.area_type.unique()

"""#DATA CLEANING"""

df.head()

x=df["size"]
x.head()

df['BHK']=df["size"].str.split(expand=True)[0]

df.head()

df.drop("size",axis=1,inplace=True)

df.total_sqft.unique()

"""cleaning multing string to number"""

def is_float(x):
  dub=x.split("-")
  if len(dub)==2:
    return (float(dub[0])+float(dub[1]))/2
  try:
    return float(x)
  except:
    return None

df["total_sqft"]=df["total_sqft"].apply(is_float)

df["total_sqft"].isna().sum()

"""Filtering Data"""

df=df[['area_type','location','total_sqft','bath','balcony','BHK','price']]
df.head()

df.isna().sum()

df.balcony.fillna(df.balcony.median(),inplace=True)

df.bath.median()

df.isna().sum()

"""Due to large data droping all NaN value"""

df.dropna(inplace=True)

df.isna().sum()

"""CHANGING DTYPE"""

df.dtypes

df.BHK=df.BHK.astype(int)

df.dtypes

"""VISULATION AND CLEANING"""

import seaborn as sn

sn.distplot(df.BHK)

df.BHK.value_counts()

df=df[df.BHK<10]

df=df[df.total_sqft/df.BHK>300]

df.groupby("BHK")["bath"].sum()

df=df[df.bath<df.BHK+1]

sn.distplot(df.bath)

"""Creating price per squre meter"""

df["price/sqmtr"]=df.price*100000/df.total_sqft

"""Change price to Lakhs"""

df["price"]=df.price*100000

df.shape

df.location.apply(lambda x: x.strip())

"""Dimensionality Reduction"""

len(df.location.unique())

location_stats=df.location.value_counts()

reducelocation=location_stats[location_stats<10]

len(reducelocation)

df.location=df.location.apply(lambda x: "other" if x in reducelocation else x)

len(df.location.unique())

df['price/sqmtr'].describe()

"""Above minimum and maximum price is outof Range"""

sn.distplot(df["price/sqmtr"])

import numpy as np
high_outlier=df["price/sqmtr"].mean()+(df["price/sqmtr"].std())
high_outlier

low_outlier=df["price/sqmtr"].mean()-(df["price/sqmtr"].std())
low_outlier

df=df[(df["price/sqmtr"]>low_outlier)&(df["price/sqmtr"]<high_outlier)]
df

df["price/sqmtr"].describe()

sn.distplot(df["price/sqmtr"])

df.price.describe()

import matplotlib.pyplot as plt
plt.figure(figsize=(12,8))
plt.title("Kothanur")
sn.scatterplot(data=df[(df['location']=="Kothanur")],x="price/sqmtr",y="price",hue="area_type")

df.corr()

plt.figure(figsize=(15,10))
plt.title("Kothanur")
sn.scatterplot(data=df8[df8['location']=="Kothanur"],x="price/sqmtr",y="price",hue="area_type")

df=df[df.balcony<df.BHK]

df.describe()

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
df["area_type"]=le.fit_transform(df["area_type"])

df["location"]=le.fit_transform(df["location"])

df.head()

df.dtypes

"""Above data are prefect dtype"""

x=df[["area_type",'location','total_sqft','bath','balcony',"BHK"]]
y=df["price"]

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,train_size=.7)

from sklearn.linear_model import LinearRegression
reg=LinearRegression()
reg.fit(x_train,y_train)

reg.score(x_test,y_test)

"""**Use K Fold cross validation to measure accuracy of our LinearRegression**"""

from sklearn.model_selection import cross_val_score
clf=cross_val_score(LinearRegression(),x,y,cv=6)
clf.mean()

from sklearn.tree import DecisionTreeRegressor
clf=cross_val_score(DecisionTreeRegressor(),x,y,cv=6)
clf.mean()

"""**Find best model using GridSearchCV**"""

from sklearn.svm import SVR
from sklearn.linear_model import Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor

model={
    "linerReg":{
        "model":LinearRegression(),
        "param":{
            'normalize':['deprecated',True,False]
        }
    },
    "svr":{
        "model":SVR(),
        "param":{
            'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],
            "C":[1,10,20,100]
        }
    },
    "lasso":{
        "model": Lasso(),
        "param":{
            "alpha": [1,2,3],
            'selection' : ['cyclic', 'random']
        }
    },
    "DecisionTree":{
        "model":DecisionTreeRegressor(),
        "param":{
            'criterion' : ["squared_error", "friedman_mse", "absolute_error"],
            'splitter' : ["best", "random"]
        }
    }
}

from sklearn.model_selection import GridSearchCV

score=[]
for mod,para in model.items():
  clf=GridSearchCV(para["model"],para["param"],cv=5)
  clf.fit(x,y)
  score.append({
      
      "best":clf.best_estimator_,
      "best score":clf.best_score_,
      "best_param":clf.best_params_
  })

pd.DataFrame(score)

"""**Based on above results we can say that LinearRegression & Lasso gives the best score. Hence we will use that**

lets check RandomForest also
"""

rand=cross_val_score(RandomForestRegressor(),x,y,cv=6)
rand.mean()

import warnings
warnings.filterwarnings("ignore")

x_train

#area_type	location	total_sqft	bath	balcony	BHK
reg.predict([[3,65,964.0,2.0,1.0,2]])

#area_type	location	total_sqft	bath	balcony	BHK
reg.predict([[3,65,964.0,2.0,2.0,3]])

#area_type	location	total_sqft	bath	balcony	BHK
reg.predict([[5,65,964.0,2.0,2.0,1]])

#area_type	location	total_sqft	bath	balcony	BHK
reg.predict([[8,65,1964.0,2.0,2.0,2]])

"""#Export the tested model to a joblib file"""

import joblib
joblib.dump(reg,"bangaloreLiner")

joblib.dump(rand,"bangaloreRandFrst")